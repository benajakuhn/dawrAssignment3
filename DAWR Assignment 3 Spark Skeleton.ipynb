{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8fa83ffa-577d-4843-a104-a5315ceb51fd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: scrapy in /local_disk0/.ephemeral_nfs/envs/pythonEnv-d0ddf361-27ba-4074-a796-d04c4186057d/lib/python3.9/site-packages (2.13.0)\r\nRequirement already satisfied: pyopenssl>=22.0.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-d0ddf361-27ba-4074-a796-d04c4186057d/lib/python3.9/site-packages (from scrapy) (25.1.0)\r\nRequirement already satisfied: queuelib>=1.4.2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-d0ddf361-27ba-4074-a796-d04c4186057d/lib/python3.9/site-packages (from scrapy) (1.8.0)\r\nRequirement already satisfied: cryptography>=37.0.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-d0ddf361-27ba-4074-a796-d04c4186057d/lib/python3.9/site-packages (from scrapy) (45.0.2)\r\nRequirement already satisfied: service-identity>=18.1.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-d0ddf361-27ba-4074-a796-d04c4186057d/lib/python3.9/site-packages (from scrapy) (24.2.0)\r\nRequirement already satisfied: twisted>=21.7.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-d0ddf361-27ba-4074-a796-d04c4186057d/lib/python3.9/site-packages (from scrapy) (24.11.0)\r\nRequirement already satisfied: defusedxml>=0.7.1 in /databricks/python3/lib/python3.9/site-packages (from scrapy) (0.7.1)\r\nRequirement already satisfied: itemadapter>=0.1.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-d0ddf361-27ba-4074-a796-d04c4186057d/lib/python3.9/site-packages (from scrapy) (0.11.0)\r\nRequirement already satisfied: itemloaders>=1.0.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-d0ddf361-27ba-4074-a796-d04c4186057d/lib/python3.9/site-packages (from scrapy) (1.3.2)\r\nRequirement already satisfied: packaging in /databricks/python3/lib/python3.9/site-packages (from scrapy) (21.3)\r\nRequirement already satisfied: pydispatcher>=2.0.5 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-d0ddf361-27ba-4074-a796-d04c4186057d/lib/python3.9/site-packages (from scrapy) (2.0.7)\r\nRequirement already satisfied: tldextract in /local_disk0/.ephemeral_nfs/envs/pythonEnv-d0ddf361-27ba-4074-a796-d04c4186057d/lib/python3.9/site-packages (from scrapy) (5.3.0)\r\nRequirement already satisfied: zope-interface>=5.1.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-d0ddf361-27ba-4074-a796-d04c4186057d/lib/python3.9/site-packages (from scrapy) (7.2)\r\nRequirement already satisfied: w3lib>=1.17.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-d0ddf361-27ba-4074-a796-d04c4186057d/lib/python3.9/site-packages (from scrapy) (2.3.1)\r\nRequirement already satisfied: lxml>=4.6.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-d0ddf361-27ba-4074-a796-d04c4186057d/lib/python3.9/site-packages (from scrapy) (5.4.0)\r\nRequirement already satisfied: parsel>=1.5.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-d0ddf361-27ba-4074-a796-d04c4186057d/lib/python3.9/site-packages (from scrapy) (1.10.0)\r\nRequirement already satisfied: protego>=0.1.15 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-d0ddf361-27ba-4074-a796-d04c4186057d/lib/python3.9/site-packages (from scrapy) (0.4.0)\r\nRequirement already satisfied: cssselect>=0.9.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-d0ddf361-27ba-4074-a796-d04c4186057d/lib/python3.9/site-packages (from scrapy) (1.3.0)\r\nRequirement already satisfied: cffi>=1.14 in /databricks/python3/lib/python3.9/site-packages (from cryptography>=37.0.0->scrapy) (1.15.0)\r\nRequirement already satisfied: pycparser in /databricks/python3/lib/python3.9/site-packages (from cffi>=1.14->cryptography>=37.0.0->scrapy) (2.21)\r\nRequirement already satisfied: jmespath>=0.9.5 in /databricks/python3/lib/python3.9/site-packages (from itemloaders>=1.0.1->scrapy) (0.10.0)\r\nRequirement already satisfied: typing-extensions>=4.9 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-d0ddf361-27ba-4074-a796-d04c4186057d/lib/python3.9/site-packages (from pyopenssl>=22.0.0->scrapy) (4.13.2)\r\nRequirement already satisfied: pyasn1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-d0ddf361-27ba-4074-a796-d04c4186057d/lib/python3.9/site-packages (from service-identity>=18.1.0->scrapy) (0.6.1)\r\nRequirement already satisfied: attrs>=19.1.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-d0ddf361-27ba-4074-a796-d04c4186057d/lib/python3.9/site-packages (from service-identity>=18.1.0->scrapy) (25.3.0)\r\nRequirement already satisfied: pyasn1-modules in /local_disk0/.ephemeral_nfs/envs/pythonEnv-d0ddf361-27ba-4074-a796-d04c4186057d/lib/python3.9/site-packages (from service-identity>=18.1.0->scrapy) (0.4.2)\r\nRequirement already satisfied: automat>=24.8.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-d0ddf361-27ba-4074-a796-d04c4186057d/lib/python3.9/site-packages (from twisted>=21.7.0->scrapy) (25.4.16)\r\nRequirement already satisfied: hyperlink>=17.1.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-d0ddf361-27ba-4074-a796-d04c4186057d/lib/python3.9/site-packages (from twisted>=21.7.0->scrapy) (21.0.0)\r\nRequirement already satisfied: constantly>=15.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-d0ddf361-27ba-4074-a796-d04c4186057d/lib/python3.9/site-packages (from twisted>=21.7.0->scrapy) (23.10.4)\r\nRequirement already satisfied: incremental>=24.7.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-d0ddf361-27ba-4074-a796-d04c4186057d/lib/python3.9/site-packages (from twisted>=21.7.0->scrapy) (24.7.2)\r\nRequirement already satisfied: idna>=2.5 in /databricks/python3/lib/python3.9/site-packages (from hyperlink>=17.1.1->twisted>=21.7.0->scrapy) (3.3)\r\nRequirement already satisfied: setuptools>=61.0 in /databricks/python3/lib/python3.9/site-packages (from incremental>=24.7.0->twisted>=21.7.0->scrapy) (61.2.0)\r\nRequirement already satisfied: tomli in /databricks/python3/lib/python3.9/site-packages (from incremental>=24.7.0->twisted>=21.7.0->scrapy) (1.2.2)\r\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /databricks/python3/lib/python3.9/site-packages (from packaging->scrapy) (3.0.4)\r\nRequirement already satisfied: requests-file>=1.4 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-d0ddf361-27ba-4074-a796-d04c4186057d/lib/python3.9/site-packages (from tldextract->scrapy) (2.1.0)\r\nRequirement already satisfied: requests>=2.1.0 in /databricks/python3/lib/python3.9/site-packages (from tldextract->scrapy) (2.27.1)\r\nRequirement already satisfied: filelock>=3.0.8 in /usr/local/lib/python3.9/dist-packages (from tldextract->scrapy) (3.9.0)\r\nRequirement already satisfied: charset-normalizer~=2.0.0 in /databricks/python3/lib/python3.9/site-packages (from requests>=2.1.0->tldextract->scrapy) (2.0.4)\r\nRequirement already satisfied: certifi>=2017.4.17 in /databricks/python3/lib/python3.9/site-packages (from requests>=2.1.0->tldextract->scrapy) (2021.10.8)\r\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /databricks/python3/lib/python3.9/site-packages (from requests>=2.1.0->tldextract->scrapy) (1.26.9)\r\n\u001B[33mWARNING: You are using pip version 21.2.4; however, version 25.1.1 is available.\r\nYou should consider upgrading via the '/local_disk0/.ephemeral_nfs/envs/pythonEnv-d0ddf361-27ba-4074-a796-d04c4186057d/bin/python -m pip install --upgrade pip' command.\u001B[0m\r\n"
     ]
    }
   ],
   "source": [
    "# run this command on databricks first, not necessary locally\n",
    "!pip install scrapy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "38924a7b-7cef-4ea1-a4d6-2c43be890d10",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Part 1 - Parsing Hikes\n",
    "\n",
    "In the first part of the assignment, you need to extract the relevant attributes from the web pages scraped from hikr.org. Extend the `parse` function so that it extracts all the attributes you need to create the ranking. You may define your own helper functions and extend the `parse` function as necessary. Just keep in mind that the arguments/result types should not be changed to enable you to use the function in the second part of the assignment.\n",
    "\n",
    "## Chosen Features\n",
    "The follwing features are extracted from the hikr.org tour pages:\n",
    "\n",
    "### 1. Region (`region`)\n",
    "A string representing the tour's geographical region, as a breadcrumb path (e.g., \"World » Italy » Lombardy\") <br>\n",
    "**Cleaning:** Individual parts are whitespace-trimmed and joined by \" » \". It will be `None` if not found or if all parts are empty.\n",
    "\n",
    "### 2. Tour Date (`tour_date`)\n",
    "The date of the tour, formatted as a \"dd.mm.yyyy\" string (e.g., \"05.06.2010\"). <br>\n",
    "**Cleaning:** The day and month are zero-padded. It will be `None` if the original date string is not found, is in an unexpected format, or contains an unrecognized month name.\n",
    "\n",
    "### 3. Descent in Meters (`descent_meters`)\n",
    "The total descent of the tour in meters. <br>\n",
    "**Cleaning:** The \"m\" unit removed and all letters converted to lowercase (e.g., \"600\"). Leading/trailing whitespace removed. It will be `None` if not found.\n",
    "\n",
    "### 4. Ascent in Meters (`ascent_meters`)\n",
    "The total ascent of the tour in meters. <br>\n",
    "**Cleaning:** The \"m\" unit removed and all letters converted to lowercase (e.g., \"600\"). Leading/trailing whitespace removed. It will be `None` if not found.\n",
    "\n",
    "### 5. Peaks (`peaks`)\n",
    "A list representing the names of the peaks visited during the tour. <br>\n",
    "**Cleaning:** It will be `None` if no peaks are found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-21T13:00:03.507048Z",
     "start_time": "2025-05-21T13:00:02.778296Z"
    },
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "716140a3-fd70-489b-af13-73e2edd565bb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import scrapy\n",
    "from scrapy.selector import Selector\n",
    "\n",
    "# Parses a hikr.org tour and extracts all the attributes we are interested in.\n",
    "# Parameters:\n",
    "#   tour: HTML Content of the hikr.org tour.\n",
    "# Result:\n",
    "#   A dictionary containing the extracted attributes for this tour.\n",
    "def parse(tour):\n",
    "    # id is the filename, text is the file content\n",
    "    [id, text] = tour\n",
    "\n",
    "    # Parse it using scrapy\n",
    "    document = Selector(text=text)\n",
    "\n",
    "    name_raw = document.css('h1.title::text').get()\n",
    "    # Clean: remove leading/trailing whitespace. If not found, it remains None.\n",
    "    name = name_raw.strip() if name_raw else None\n",
    "\n",
    "    # 1. Region\n",
    "    region_xpath = '//tr[td[@class=\"fiche_rando_b\" and contains(normalize-space(.), \"Region:\")]]/td[@class=\"fiche_rando\"]//a/text()'\n",
    "    region_parts_raw = document.xpath(region_xpath).getall()\n",
    "    # Clean: Strip whitespace from each part, filter out any empty strings, then join with \" » \".\n",
    "    # If no parts are found, region remains None.\n",
    "    region = None\n",
    "    if region_parts_raw:\n",
    "        cleaned_parts = [part.strip() for part in region_parts_raw if part.strip()]\n",
    "        if cleaned_parts:\n",
    "            region = ' » '.join(cleaned_parts)\n",
    "\n",
    "    # 2. Tour Date\n",
    "    tour_date_xpath = '//tr[td[@class=\"fiche_rando_b\" and contains(normalize-space(.), \"Tour Datum:\")]]/td[@class=\"fiche_rando\"]/text()'\n",
    "    tour_date_raw_str = document.xpath(tour_date_xpath).get()\n",
    "\n",
    "    tour_date = None\n",
    "    if tour_date_raw_str:\n",
    "        # Clean: remove leading/trailing whitespace.\n",
    "        cleaned_date_str = tour_date_raw_str.strip()\n",
    "        # German month names to month number mapping\n",
    "        german_months = {\n",
    "            'Januar': 1, 'Februar': 2, 'März': 3, 'April': 4, 'Mai': 5, 'Juni': 6,\n",
    "            'Juli': 7, 'August': 8, 'September': 9, 'Oktober': 10, 'November': 11, 'Dezember': 12\n",
    "        }\n",
    "        parts = cleaned_date_str.split()\n",
    "        if len(parts) == 3:\n",
    "            day = int(parts[0])\n",
    "            month_name = parts[1]\n",
    "            year = int(parts[2])\n",
    "\n",
    "            month_number = german_months.get(month_name)\n",
    "\n",
    "            if month_number:\n",
    "                tour_date = f\"{day:02d}.{month_number:02d}.{year}\"\n",
    "\n",
    "    # 3. Descent\n",
    "    descent_xpath = '//tr[td[@class=\"fiche_rando_b\" and contains(normalize-space(.), \"Abstieg:\")]]/td[@class=\"fiche_rando\"]/text()'\n",
    "    descent_raw_str = document.xpath(descent_xpath).get()\n",
    "    # Clean: convert to lowercase, remove \"m\", and strip whitespace.\n",
    "    descent_meters = None\n",
    "    if descent_raw_str:\n",
    "        descent_meters = descent_raw_str.lower().replace('m', '').strip()\n",
    "\n",
    "    # 4. Ascent\n",
    "    ascent_xpath = '//tr[td[@class=\"fiche_rando_b\" and contains(normalize-space(.), \"Aufstieg:\")]]/td[@class=\"fiche_rando\"]/text()'\n",
    "    ascent_raw = document.xpath(ascent_xpath).get()\n",
    "    # Clean: convert to lowercase, remove \"m\", and strip whitespace.\n",
    "    ascent_meters = None\n",
    "    if ascent_raw:\n",
    "        ascent_meters = ascent_raw.lower().replace('m', '').strip()\n",
    "\n",
    "    # 5. Peaks\n",
    "    peaks_xpath = '//td[contains(text(),\"Wegpunkte:\")]/following-sibling::td//img[contains(@src, \"ico2_peak_s.png\")]/following-sibling::a/text()'\n",
    "    peaks_raw = document.xpath(peaks_xpath).getall()\n",
    "    # If there is one or more peaks, set it to the list otherwise set it to None\n",
    "    peaks = None\n",
    "    if peaks_raw:\n",
    "        peaks = peaks_raw\n",
    "\n",
    "    # Assemble the result dictionary\n",
    "    result = {\n",
    "        'name': name,\n",
    "        'region': region,\n",
    "        'tour_date': tour_date,\n",
    "        'descent_meters': descent_meters,\n",
    "        'ascent_meters': ascent_meters,\n",
    "        'peaks': peaks\n",
    "    }\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9768e05e-f8e8-4dce-9979-e734f897cb6e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "ExecuteTime": {
     "end_time": "2025-05-21T15:13:11.726462Z",
     "start_time": "2025-05-21T15:13:11.675956Z"
    }
   },
   "source": [
    "# Extract the 200posts.zip file in the same folder where this jupyter notebook is located.\n",
    "# Then you can run the parse function on an example tour:\n",
    "with open('200posts/post24013.html', 'r', encoding='utf-8') as f:\n",
    "    content = f.read()\n",
    "    r = parse([f.name, content])\n",
    "    print(r)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'Hinteres Schöneck (3128m), Ortler Alpen', 'region': 'Welt » Italien » Trentino-Südtirol', 'tour_date': '04.06.2010', 'descent_meters': '1300', 'ascent_meters': '1300', 'peaks': ['Hinteres Schöneck 3128 m   (11)', 'Vorderes Schöneck 2908 m   (5)']}\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "72a2c7d6-16ce-4c96-8841-41ebfd923fd8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Part 2 - Parallelization & Aggregation (Spark)\n",
    "\n",
    "It is highly recommended to wait with this part until after the Spark lecture!\n",
    "\n",
    "This part only works on databricks!\n",
    "\n",
    "Warning: In the community edition, databricks terminates your cluster after 2 hours of inactivity. If you re-create the cluster, you will lose your data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5c63c3a6-a4ad-4793-9138-859f1eaea18d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "To add a library such as scrapy, it might not always work with the command above. Should you run into problems, you can alternatively do the following:\n",
    "\n",
    "- Go to the \"Clusters\" panel on the left\n",
    "- Select your cluster\n",
    "- Go to the \"Libraries\" tab\n",
    "- Click \"Install New\"\n",
    "- Choose \"PyPI\" as library source\n",
    "- Type the name of the library, \"scrapy\", into the package field\n",
    "- Click \"Install\"\n",
    "- Wait until the installation has finished\n",
    "\n",
    "You can now use the newly installed library in your code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "76eabc05-2c4a-47da-92b5-169e279fa5b5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# AWS Access configuration\n",
    "sc._jsc.hadoopConfiguration().set(\"fs.s3n.awsAccessKeyId\", \"AKIAYFVAOB5OOWVMUSCZ\")\n",
    "sc._jsc.hadoopConfiguration().set(\"fs.s3n.awsSecretAccessKey\", \"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\")\n",
    "\n",
    "# Contains the whole hikr dataset.\n",
    "# The full dataset contains 42330 tours and has a size of around 3 GB. Use this dataset for your final results if possible.\n",
    "# Execution is likely to take around 20 to 30 minutes.\n",
    "# tours = sc.wholeTextFiles(\"s3a://dawr-hikr3/hikr/*.html\")\n",
    "\n",
    "# There are 8176 posts starting with \"post10*\", which is a nicer size for smaller experiments. (~ 5 minutes to process)\n",
    "# tours = sc.wholeTextFiles(\"s3a://dawr-hikr3/hikr/post10*.html\")\n",
    "\n",
    "# If you want to further shrink the dataset size for testing, you can add another zero (or more) to the pattern (post100*.html).\n",
    "tours = sc.wholeTextFiles(\"s3a://dawr-hikr3/hikr/post10*.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "969dcc15-b5bb-4763-b10d-8188f446fabc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Apply our parse function and persist the parse results so that we can repeat all further steps easier\n",
    "import pyspark\n",
    "parsedTours = tours.map(parse).persist(pyspark.StorageLevel.MEMORY_AND_DISK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "98c18122-0ca9-4421-a7a0-e5cbe2bf9746",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Out[64]: 8176"
     ]
    }
   ],
   "source": [
    "# actually force the parsedTours RDD. Above it was only defined, but not evaluated. This will take a while.\n",
    "parsedTours.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fd3276d9-9ed2-4623-aadd-7d2b2c3fff49",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql import Row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fac21374-0e18-4c64-af87-de64d6516f44",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Filtering\n",
    "In this section filtering of the peaks will be done. This will help select the perfect peak for the tour this summer.\n",
    "This will happen in multiple steps:\n",
    "\n",
    "## Region Filtering\n",
    "Since the main language of the participants of the tour is german. To make the feel at home, only tours that are in Switzerland or one of its german-speaking neighbors will be kept.\n",
    "\n",
    "## Date Filtering\n",
    "Tours can change over time due to weather conditions and other factors. Therefore it is important to plan based on current data. Due to this, only tours that are newer than the 1st of January 2015 will be kept.\n",
    "\n",
    "## Descent Filtering\n",
    "Generally, people prefer tours that don't have a big descent. Long descents are hard on the knees and can be dangerous. Therefore, all tours that have a greater descent than ascent will be filtered out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0d47eb26-ae76-4404-b2ad-10e48dfd03e2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Original tour count: 8176\nFiltered Region tour count: 5573\nFiltered Date tour count: 4624\nFiltered Descent tour count: 4076\n"
     ]
    }
   ],
   "source": [
    "# save the parsedTours to a DataFrame\n",
    "df_tours = spark.createDataFrame(parsedTours.collect())\n",
    "\n",
    "# Only keep the german speaking neighbors of Switzerland including Switzerland\n",
    "countries_to_keep = [\n",
    "    'Schweiz',   \n",
    "    'Deutschland',  \n",
    "    'Österreich',  \n",
    "    'Liechtenstein' \n",
    "]\n",
    "\n",
    "print(f\"Original tour count: {df_tours.count()}\")\n",
    "\n",
    "# Create a filter condition, that only becomes true when the condition is met and then stays true\n",
    "filter_condition = lit(False)\n",
    "for country in countries_to_keep:\n",
    "    filter_condition = filter_condition | col('region').contains(country)\n",
    "\n",
    "# Apply the filter to the DataFrame\n",
    "df_tours_filtered = df_tours.filter(filter_condition)\n",
    "\n",
    "print(f\"Filtered Region tour count: {df_tours_filtered.count()}\")\n",
    "\n",
    "# Convert the tour_date column to a date type\n",
    "df_tours_with_date = df_tours_filtered.withColumn(\"parsed_tour_date\", to_date(col(\"tour_date\"), \"dd.MM.yyyy\"))\n",
    "\n",
    "# Define cutoff date\n",
    "cutoff_date = to_date(lit(\"01.01.2015\"), \"dd.MM.yyyy\")\n",
    "\n",
    "# Filter to keep tours on or after the cutoff date\n",
    "df_tours_filtered = df_tours_with_date.filter(col(\"parsed_tour_date\") >= cutoff_date).drop(\"parsed_tour_date\")\n",
    "\n",
    "print(f\"Filtered Date tour count: {df_tours_filtered.count()}\")\n",
    "\n",
    "# Ensure that the ascent and descent values are numeric\n",
    "df_tours_numeric_metrics = df_tours_filtered.withColumn(\"ascent_val\", col(\"ascent_meters\").cast(\"float\")).withColumn(\"descent_val\", col(\"descent_meters\").cast(\"float\"))\n",
    "\n",
    "# Filter to keep tours where the ascent is greater than or equal to the descent\n",
    "df_tours_filtered = df_tours_numeric_metrics.filter(\n",
    "    (when(col(\"descent_val\").isNull(), 0).otherwise(col(\"descent_val\")) <=\n",
    "     when(col(\"ascent_val\").isNull(), 0).otherwise(col(\"ascent_val\")))\n",
    ").drop(\"ascent_val\", \"descent_val\")\n",
    "\n",
    "print(f\"Filtered Descent tour count: {df_tours_filtered.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dff3fac3-ad2e-475e-87ee-54fc8dbb69a3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+-------------+--------------+--------------------+--------------------+--------------------+----------+\n|ascent_meters|descent_meters|                name|               peaks|              region| tour_date|\n+-------------+--------------+--------------------+--------------------+--------------------+----------+\n|          700|           700|Läged Windgällen ...|[Chli Geissberg 1...|Welt » Schweiz » Uri|27.09.2015|\n|          720|           720|     Iseler im Nebel|[Iseler 1876 m   ...|Welt » Österreich...|27.09.2015|\n|          450|           450|Monte Tamaro - (a...|[Monte Tamaro 196...|Welt » Schweiz » ...|20.09.2015|\n|          200|           200|Rund um den See (...|                null|Welt » Schweiz » Uri|27.09.2015|\n|          650|           650|    Taborberg 1'618m|                null|Welt » Österreich...|27.09.2015|\n|          350|           350|Gipfelsammeln im ...|[Predigtstuhl 161...|Welt » Deutschlan...|28.09.2015|\n|         1050|          1050|La Maya (St Marti...|[La Maya 2916 m  ...|Welt » Schweiz » ...|26.09.2015|\n|         null|          null|Gamsspitz und Piz...|[Pizzo Centrale 2...|Welt » Schweiz » ...|26.09.2015|\n|          700|           700|Chemiflue/Chemige...|[Kleine Chemiflue...|Welt » Schweiz » ...|27.09.2015|\n|          730|          null|Herbstmessungen C...|                null|Welt » Schweiz » ...|19.09.2015|\n|          600|          null|Herbstmessungen F...|                null|Welt » Schweiz » ...|21.09.2015|\n|         1900|          1100|Bike & Hike auf d...|[Wissgandstock / ...|Welt » Schweiz » ...|29.09.2015|\n|         1375|           880|      Zuestoll 2235m|[Zuestoll 2234 m ...|Welt » Schweiz » ...|29.09.2015|\n|         1400|           600|Sassauna 2308 m -...|[Sassauna 2308 m ...|Welt » Schweiz » ...|29.09.2015|\n|         2000|          2000| Rund ums Trainsjoch|                null|Welt » Deutschlan...|29.09.2015|\n|         null|          null|Breite Kluft, Wil...|[Carolafelsen 442...|Welt » Deutschlan...|28.09.2015|\n|         null|          null|die mondfinsterni...|[Berchtesgadener ...|Welt » Deutschlan...|28.09.2015|\n|          400|           310|Über den Sommersb...|                null|Welt » Schweiz » ...|29.09.2015|\n|          700|          null|Nördlicher Elfert...|[Nördlicher Elfer...|Welt » Österreich...|11.09.2015|\n|         2040|          2040|Hochkalterübersch...|[Hochkalter 2607 ...|Welt » Deutschlan...|29.09.2015|\n+-------------+--------------+--------------------+--------------------+--------------------+----------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "df_tours_filtered.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "864ad71f-da27-478f-a858-dab00ffcdccb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Part 2 Final ranking\n",
    "List your final top 10 mountain peaks that occur the most often within your filtered tours. State how you handle cases where two peaks occur the same number of times.\n",
    "\n",
    "### Special case handling\n",
    "The code first expands tours with multiple peaks into individual rows, then groups them to count occurrences and sum total ascent/descent to get the total height meters. Finally, it lists the top 10 peaks, prioritizing frequency and then total height meters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aeb641b9-2810-48f6-bc65-2ca4166e1087",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+------------------------------------------+-----+-------------------+\n|peaks                                     |count|total_height_meters|\n+------------------------------------------+-----+-------------------+\n|Monte Lema 1621 m   (153)                 |18   |34560.0            |\n|Balmfluechöpfli 1289 m   (153)            |17   |17068.0            |\n|Monte Gradiccioli 1936 m   (140)          |14   |33400.0            |\n|Monte Generoso / Calvagione 1701 m   (246)|14   |25920.0            |\n|Grosser Mythen 1898 m   (225)             |13   |18380.0            |\n|Röti 1395 m   (117)                       |13   |15268.0            |\n|Moncucco 1518 m   (41)                    |12   |20060.0            |\n|Säntis 2502 m   (409)                     |11   |18879.0            |\n|Schnebelhorn 1292 m   (180)               |11   |18743.0            |\n|Rigi Kulm 1798 m   (206)                  |11   |10669.0            |\n+------------------------------------------+-----+-------------------+\n\n"
     ]
    }
   ],
   "source": [
    "# This flattens the data so each row represents a single peak associated with a tour\n",
    "df_peaks = df_tours_filtered.withColumn(\"peaks\", explode(df_tours_filtered.peaks))\n",
    "\n",
    "# Create a view to let SQL queries run directly on the DataFrame\n",
    "df_peaks.createOrReplaceTempView(\"peak_ranking\")\n",
    "\n",
    "ranking_query = \"\"\"\n",
    "SELECT\n",
    "  peaks,\n",
    "  COUNT(*) as count,\n",
    "  SUM(ascent_meters + descent_meters) as total_height_meters\n",
    "FROM \n",
    "  peak_ranking\n",
    "GROUP BY \n",
    "  peaks\n",
    "ORDER BY \n",
    "  count DESC,\n",
    "  total_height_meters DESC\n",
    "LIMIT 10\n",
    "\"\"\"\n",
    "\n",
    "ranking_df = spark.sql(ranking_query)\n",
    "ranking_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ce4908c4-24ea-4e60-8d53-6848d1d88f6a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Part 3 - Analysis of data quality\n",
    "Add further code for analysis of data quality here. Don't forget to include at least one aggregation, such as average tour length per season."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fba5317f-1336-4d33-b2e0-76a443fc4f3a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "DAWR Assignment 3 Spark Skeleton",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
