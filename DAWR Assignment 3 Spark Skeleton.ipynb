{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "38924a7b-7cef-4ea1-a4d6-2c43be890d10",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Part 1 - Parsing Hikes\n",
    "\n",
    "In the first part of the assignment, you need to extract the relevant attributes from the web pages scraped from hikr.org. Extend the `parse` function so that it extracts all the attributes you need to create the ranking. You may define your own helper functions and extend the `parse` function as necessary. Just keep in mind that the arguments/result types should not be changed to enable you to use the function in the second part of the assignment."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "716140a3-fd70-489b-af13-73e2edd565bb",
     "showTitle": false,
     "title": ""
    },
    "ExecuteTime": {
     "end_time": "2025-05-15T12:34:54.377466Z",
     "start_time": "2025-05-15T12:34:53.825699Z"
    }
   },
   "source": [
    "import scrapy\n",
    "from scrapy.selector import Selector\n",
    "\n",
    "# Parses a hikr.org tour and extracts all the attributes we are interested in.\n",
    "# Parameters:\n",
    "#   tour: HTML Content of the hikr.org tour.\n",
    "# Result:\n",
    "#   A dictionary containing the extracted attributes for this tour.\n",
    "def parse(tour):\n",
    "    # id is the filename, text is the file content\n",
    "    [id, text] = tour\n",
    "    # Parse it using scrapy\n",
    "    document = Selector(text=text)\n",
    "    # Do some extraction\n",
    "\n",
    "    # TODO: Extract more attributes and add them to the result dictionary!\n",
    "    result = {\n",
    "        'name': document.css('h1.title::text').get()\n",
    "    }\n",
    "    return result"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "9768e05e-f8e8-4dce-9979-e734f897cb6e",
     "showTitle": false,
     "title": ""
    },
    "ExecuteTime": {
     "end_time": "2025-05-15T12:34:56.530839Z",
     "start_time": "2025-05-15T12:34:56.362685Z"
    }
   },
   "source": [
    "# Extract the 200posts.zip file in the same folder where this jupyter notebook is located.\n",
    "# Then you can run the parse function on an example tour:\n",
    "with open('200posts/post24010.html') as f:\n",
    "    content = f.read()\n",
    "    r = parse([f.name, content])\n",
    "    print(r)\n"
   ],
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '200posts/post24010.html'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[2], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# Extract the 200posts.zip file in the same folder where this jupyter notebook is located.\u001B[39;00m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;66;03m# Then you can run the parse function on an example tour:\u001B[39;00m\n\u001B[1;32m----> 3\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m200posts/post24010.html\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mas\u001B[39;00m f:\n\u001B[0;32m      4\u001B[0m     content \u001B[38;5;241m=\u001B[39m f\u001B[38;5;241m.\u001B[39mread()\n\u001B[0;32m      5\u001B[0m     r \u001B[38;5;241m=\u001B[39m parse([f\u001B[38;5;241m.\u001B[39mname, content])\n",
      "File \u001B[1;32m~\\OneDrive - FHNW\\Documents\\FHNW\\HS24\\dist\\jupyter\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:324\u001B[0m, in \u001B[0;36m_modified_open\u001B[1;34m(file, *args, **kwargs)\u001B[0m\n\u001B[0;32m    317\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m file \u001B[38;5;129;01min\u001B[39;00m {\u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m2\u001B[39m}:\n\u001B[0;32m    318\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    319\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mIPython won\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt let you open fd=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfile\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m by default \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    320\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    321\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124myou can use builtins\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m open.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    322\u001B[0m     )\n\u001B[1;32m--> 324\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mio_open\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfile\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: '200posts/post24010.html'"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "72a2c7d6-16ce-4c96-8841-41ebfd923fd8",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Part 2 - Parallelization & Aggregation (Spark)\n",
    "\n",
    "It is highly recommended to wait with this part until after the Spark lecture!\n",
    "\n",
    "This part only works on databricks!\n",
    "\n",
    "Warning: In the community edition, databricks terminates your cluster after 2 hours of inactivity. If you re-create the cluster, you will lose your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scrapy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To add a library such as scrapy, it might not always work with the command above. Should you run into problems, you can alternatively do the following:\n",
    "\n",
    "- Go to the \"Clusters\" panel on the left\n",
    "- Select your cluster\n",
    "- Go to the \"Libraries\" tab\n",
    "- Click \"Install New\"\n",
    "- Choose \"PyPI\" as library source\n",
    "- Type the name of the library, \"scrapy\", into the package field\n",
    "- Click \"Install\"\n",
    "- Wait until the installation has finished\n",
    "\n",
    "You can now use the newly installed library in your code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "76eabc05-2c4a-47da-92b5-169e279fa5b5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# AWS Access configuration\n",
    "# sc._jsc.hadoopConfiguration().set(\"fs.s3n.awsAccessKeyId\", \"AKIAXLOQRT47SHG4WZNH\") # old key\n",
    "# sc._jsc.hadoopConfiguration().set(\"fs.s3n.awsSecretAccessKey\", \"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\") # old secret\n",
    "sc._jsc.hadoopConfiguration().set(\"fs.s3n.awsAccessKeyId\", \"AKIAYFVAOB5OOWVMUSCZ\")\n",
    "sc._jsc.hadoopConfiguration().set(\"fs.s3n.awsSecretAccessKey\", \"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\")\n",
    "\n",
    "# Contains the whole hikr dataset.\n",
    "# The full dataset contains 86101 tours and has a size of around 4.8 GB.\n",
    "# There are 46854 posts starting with \"post1*\". Use this dataset for your final results if possible. Execution is likely to take around 30~45 minutes.\n",
    "# There are 8176 posts starting with \"post10*\", which is a nicer size for smaller experiments.\n",
    "# If you want to further shrink the dataset size for testing, you can add another zero to the pattern (post100*.html).\n",
    "# tours = sc.wholeTextFiles(\"s3a://dawr-hikr/post1000*.html\") # old url\n",
    "tours = sc.wholeTextFiles(\"s3://dawr-hikr2/post1000*.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "969dcc15-b5bb-4763-b10d-8188f446fabc",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Apply our parse function and persist the parse results so that we can repeat all further steps easier\n",
    "import pyspark\n",
    "parsedTours = tours.map(parse).persist(pyspark.StorageLevel.MEMORY_AND_DISK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "98c18122-0ca9-4421-a7a0-e5cbe2bf9746",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# actually force the parsedTours RDD. Above it was only defined, but not evaluated. This will take a while.\n",
    "parsedTours.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "0d47eb26-ae76-4404-b2ad-10e48dfd03e2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO\n",
    "# Add your code here. Note that executing this cell and any below can reuse the results from \"parsedTours\".\n",
    "\n",
    "# Example - let's just collect everything\n",
    "parsedTours.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "f508f8d5-64bb-4744-8941-067ad0db8c16",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "DAWR Assignment 3 Spark Skeleton",
   "notebookOrigID": 3995684355508196,
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
